{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Twin KPI Sanity Check\n",
    "\n",
    "**Purpose**: Validate digital twin KPI predictions against ground truth data\n",
    "\n",
    "**Author**: Analytics Team  \n",
    "**Last Updated**: 2025-01-XX  \n",
    "**Version**: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predicted KPIs from digital twin\n",
    "predicted = pd.read_csv('../../../10-METRICS/kpi_predictions.csv')\n",
    "\n",
    "# Load actual KPIs from flight data\n",
    "actual = pd.read_csv('../../../10-METRICS/kpi_actuals.csv')\n",
    "\n",
    "# Merge on timestamp and flight ID\n",
    "df = pd.merge(predicted, actual, on=['timestamp', 'flight_id'], suffixes=('_pred', '_actual'))\n",
    "\n",
    "print(f\"Loaded {len(df)} data points\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuel Consumption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for fuel consumption\n",
    "fuel_pred = df['h2_fuel_kg_pred']\n",
    "fuel_actual = df['h2_fuel_kg_actual']\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(fuel_actual, fuel_pred))\n",
    "mae = mean_absolute_error(fuel_actual, fuel_pred)\n",
    "r2 = r2_score(fuel_actual, fuel_pred)\n",
    "mape = np.mean(np.abs((fuel_actual - fuel_pred) / fuel_actual)) * 100\n",
    "\n",
    "print(f\"Fuel Consumption Prediction Metrics:\")\n",
    "print(f\"  RMSE: {rmse:.2f} kg\")\n",
    "print(f\"  MAE: {mae:.2f} kg\")\n",
    "print(f\"  R²: {r2:.4f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Requirement: >95% accuracy (MAPE <5%)\n",
    "if mape < 5.0:\n",
    "    print(\"\\n✓ PASSED: Fuel prediction meets accuracy requirement\")\n",
    "else:\n",
    "    print(f\"\\n✗ FAILED: Fuel prediction MAPE {mape:.2f}% exceeds 5% threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(fuel_actual, fuel_pred, alpha=0.5, s=10)\n",
    "ax.plot([fuel_actual.min(), fuel_actual.max()], \n",
    "        [fuel_actual.min(), fuel_actual.max()], \n",
    "        'r--', lw=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual H₂ Fuel Consumption (kg)')\n",
    "ax.set_ylabel('Predicted H₂ Fuel Consumption (kg)')\n",
    "ax.set_title('Digital Twin Fuel Prediction Accuracy')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = fuel_pred - fuel_actual\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residual histogram\n",
    "axes[0].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='r', linestyle='--', lw=2)\n",
    "axes[0].set_xlabel('Prediction Error (kg)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Residual Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual vs predicted\n",
    "axes[1].scatter(fuel_pred, residuals, alpha=0.5, s=10)\n",
    "axes[1].axhline(0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted H₂ Fuel (kg)')\n",
    "axes[1].set_ylabel('Residual (kg)')\n",
    "axes[1].set_title('Residual vs Predicted Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction drift over time\n",
    "df['date'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "daily_metrics = df.groupby('date').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'mape': np.mean(np.abs((x['h2_fuel_kg_actual'] - x['h2_fuel_kg_pred']) / x['h2_fuel_kg_actual'])) * 100,\n",
    "        'count': len(x)\n",
    "    })\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(daily_metrics.index, daily_metrics['mape'], marker='o', linewidth=2)\n",
    "ax.axhline(5.0, color='r', linestyle='--', lw=2, label='Requirement threshold (5%)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('MAPE (%)')\n",
    "ax.set_title('Daily Prediction Error Trend')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Total Samples': len(df),\n",
    "    'RMSE (kg)': rmse,\n",
    "    'MAE (kg)': mae,\n",
    "    'R²': r2,\n",
    "    'MAPE (%)': mape,\n",
    "    'Requirement': '<5% MAPE',\n",
    "    'Status': 'PASS' if mape < 5.0 else 'FAIL'\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "print(\"\\n=== KPI Sanity Check Summary ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary to file\n",
    "summary_df.to_csv('kpi_sanity_summary.csv', index=False)\n",
    "print(\"\\nSummary saved to kpi_sanity_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
